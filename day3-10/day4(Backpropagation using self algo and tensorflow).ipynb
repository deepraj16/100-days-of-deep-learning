{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98a2ee4-ea66-4378-860f-c6a39eb9770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regression proplem\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2744ffb2-8c95-4773-8227-e91ef52916d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>lpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  lpa\n",
       "0     8              8    4\n",
       "1     7              9    5\n",
       "2     6             10    6\n",
       "3     5             12    7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame([[8,8,4],[7,9,5],[6,10,6],[5,12,7]],columns=['cgpa','profile_score','lpa'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b39ee17-faa7-4835-9923-befd56bc6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dies): \n",
    "    np.random.seed(3) \n",
    "    parameter ={}\n",
    "    L=len(layer_dies)\n",
    "    for i in range(1,L): \n",
    "        parameter['W'+ str(i)] = np.ones((layer_dies[i-1],layer_dies[i]))*0.1 \n",
    "        parameter['b' + str(i)]=np.zeros((layer_dies[i],1))\n",
    "\n",
    "    return parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb933ba-1856-4ab1-9db1-11a371539e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.1, 0.1],\n",
       "        [0.1, 0.1]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[0.1],\n",
       "        [0.1]]),\n",
       " 'b2': array([[0.]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e718ba1-22af-4878-af5c-63f3c9d17e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def liner_forword(A_pre,W,b) : # tell me about the Output of layers\n",
    "    Z=np.dot(W.T,A_pre) # preves layer outuput === A_pre\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7225fd50-4c5a-4ea1-aa6e-3301c56359b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layers_forward(X,parameters):  # it will make forword propogation for me\n",
    "    A=X \n",
    "    L=len(parameters)//2\n",
    "    for l in range(1,L+1): \n",
    "        A_prev =A \n",
    "        W1=parameters['W'+str(l)]\n",
    "        b1=parameters['b'+str(l)]\n",
    "        print(\"A\"+str(l-1)+\": \",A_prev)\n",
    "        print(\"W\"+str(l)+\": \",W1)\n",
    "        print(\"b\"+str(l)+\": \",b1)\n",
    "        print(\"--\"*20)\n",
    "\n",
    "        A=liner_forword(A_prev,W1,b1) # calulating the weigth for give data \n",
    "        print(\"A\"+str(l)+\": \",A)\n",
    "        print(\"***\"*20)\n",
    "\n",
    "    return A,A_prev\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ffa502a-b702-447d-877b-3cca56e6d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['cgpa','profile_score']].values[0].reshape(2,1)\n",
    "y=df[['lpa']].values[0][0]\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9227ec5f-6035-48c7-bca3-07ab63c32ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8],\n",
       "       [8]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # first student values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68f8b3c1-53ff-4942-80c1-135a272cf5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # output of sencond student \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8fee11f-46a0-4528-806e-266ad1cbb3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "************************************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.32]]),\n",
       " array([[1.6],\n",
       "        [1.6]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_layers_forward(X,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d88503f8-d590-4f54-8a48-4e3a7e45e2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.5424"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y-0.32)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d54b751-baa2-4f2e-a6f8-712e43ce12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the loss manully for data \n",
    "\n",
    "def update_parameters(parameters,y,y_hat,A1,X):\n",
    "  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.0001 * (y - y_hat)*A1[0][0])\n",
    "  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat)*A1[1][0])\n",
    "  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat))\n",
    "\n",
    "  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n",
    "  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n",
    "  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n",
    "\n",
    "  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n",
    "  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n",
    "  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e78da425-f12e-4959-840b-065ca3cd0a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "************************************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09971571, 0.09971571],\n",
       "        [0.09971571, 0.09971571]]),\n",
       " 'b1': array([[-3.55360113e-05],\n",
       "        [-3.55360113e-05]]),\n",
       " 'W2': array([[0.1005888],\n",
       "        [0.1005888]]),\n",
       " 'b2': array([[0.1009568]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "y = df[['lpa']].values[0][0]\n",
    "\n",
    "# Parameter initialization\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "\n",
    "y_hat,A1 = L_layers_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "085ea359-e1d7-482f-a690-76563ac381f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09971571 0.09971571]\n",
      " [0.09971571 0.09971571]]\n",
      "b1:  [[-3.55360113e-05]\n",
      " [-3.55360113e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[1.59545139]\n",
      " [1.59545139]]\n",
      "************************************************************\n",
      "A1:  [[1.59545139]\n",
      " [1.59545139]]\n",
      "W2:  [[0.1005888]\n",
      " [0.1005888]]\n",
      "b2:  [[0.1009568]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32096908]]\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.0994004 , 0.09931031],\n",
       "        [0.0994004 , 0.09931031]]),\n",
       " 'b1': array([[-8.05810157e-05],\n",
       "        [-8.05810157e-05]]),\n",
       " 'W2': array([[0.10133532],\n",
       "        [0.10133532]]),\n",
       " 'b2': array([[0.10180322]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training exaplme)\n",
    "y = df[['lpa']].values[1][0]\n",
    "\n",
    "y_hat,A1 = L_layers_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "421b0f2c-1561-4ceb-85c2-3c466a954757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.0994004  0.09931031]\n",
      " [0.0994004  0.09931031]]\n",
      "b1:  [[-8.05810157e-05]\n",
      " [-8.05810157e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[1.59040635]\n",
      " [1.58896491]]\n",
      "************************************************************\n",
      "A1:  [[1.59040635]\n",
      " [1.58896491]]\n",
      "W2:  [[0.10133532]\n",
      " [0.10133532]]\n",
      "b2:  [[0.10180322]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32218259]]\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09901885, 0.09881974],\n",
       "        [0.09902013, 0.09882139]]),\n",
       " 'b1': array([[-0.00013509],\n",
       "        [-0.00013491]]),\n",
       " 'W2': array([[0.10223832],\n",
       "        [0.1022375 ]]),\n",
       " 'b2': array([[0.10280528]])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training exaplme)\n",
    "y = df[['lpa']].values[2][0]\n",
    "\n",
    "y_hat,A1 = L_layers_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4162db1-1d22-4bf7-baf4-3f2b571a479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09901885 0.09881974]\n",
      " [0.09902013 0.09882139]]\n",
      "b1:  [[-0.00013509]\n",
      " [-0.00013491]]\n",
      "----------------------------------------\n",
      "A1:  [[1.58431305]\n",
      " [1.58113067]]\n",
      "************************************************************\n",
      "A1:  [[1.58431305]\n",
      " [1.58113067]]\n",
      "W2:  [[0.10223832]\n",
      " [0.1022375 ]]\n",
      "b2:  [[0.10280528]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32362836]]\n",
      "************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09857195, 0.09824516],\n",
       "        [0.09857657, 0.0982511 ]]),\n",
       " 'b1': array([[-0.00019893],\n",
       "        [-0.00019827]]),\n",
       " 'W2': array([[0.10329607],\n",
       "        [0.10329312]]),\n",
       " 'b2': array([[0.10396076]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cgpa', 'profile_score']].values[1].reshape(2,1) # Shape(no of features, no. of training exaplme)\n",
    "y = df[['lpa']].values[3][0]\n",
    "\n",
    "y_hat,A1 = L_layers_forward(X,parameters)\n",
    "y_hat = y_hat[0][0]\n",
    "\n",
    "update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "500efa20-97f9-43ca-baa3-64f7de7adaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1:  [[0.]\n",
      " [0.]]\n",
      "----------------------------------------\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "************************************************************\n",
      "A1:  [[1.6]\n",
      " [1.6]]\n",
      "W2:  [[0.1]\n",
      " [0.1]]\n",
      "b2:  [[0.]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32]]\n",
      "************************************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09971571 0.09971571]\n",
      " [0.09971571 0.09971571]]\n",
      "b1:  [[-3.55360113e-05]\n",
      " [-3.55360113e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[1.59545139]\n",
      " [1.59545139]]\n",
      "************************************************************\n",
      "A1:  [[1.59545139]\n",
      " [1.59545139]]\n",
      "W2:  [[0.1005888]\n",
      " [0.1005888]]\n",
      "b2:  [[0.1009568]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32096908]]\n",
      "************************************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.0994004  0.09931031]\n",
      " [0.0994004  0.09931031]]\n",
      "b1:  [[-8.05810157e-05]\n",
      " [-8.05810157e-05]]\n",
      "----------------------------------------\n",
      "A1:  [[1.59040635]\n",
      " [1.58896491]]\n",
      "************************************************************\n",
      "A1:  [[1.59040635]\n",
      " [1.58896491]]\n",
      "W2:  [[0.10133532]\n",
      " [0.10133532]]\n",
      "b2:  [[0.10180322]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32218259]]\n",
      "************************************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.09907335 0.09876523]\n",
      " [0.09907445 0.09876706]]\n",
      "b1:  [[-0.00013509]\n",
      " [-0.00013491]]\n",
      "----------------------------------------\n",
      "A1:  [[1.68426017]\n",
      " [1.67903092]]\n",
      "************************************************************\n",
      "A1:  [[1.68426017]\n",
      " [1.67903092]]\n",
      "W2:  [[0.10223832]\n",
      " [0.1022375 ]]\n",
      "b2:  [[0.10280528]]\n",
      "----------------------------------------\n",
      "A2:  [[0.34385586]]\n",
      "************************************************************\n",
      "Epoch -  1 Loss -  27.99439892095031\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09867692 0.09781379]\n",
      " [0.09868228 0.09782586]]\n",
      "b1:  [[-0.00021438]\n",
      " [-0.00021334]]\n",
      "----------------------------------------\n",
      "A1:  [[1.57887359]\n",
      " [1.56511717]]\n",
      "************************************************************\n",
      "A1:  [[1.57887359]\n",
      " [1.56511717]]\n",
      "W2:  [[0.10335939]\n",
      " [0.10335509]]\n",
      "b2:  [[0.1040207]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32495423]]\n",
      "************************************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09839762 0.09753449]\n",
      " [0.09841202 0.0975556 ]]\n",
      "b1:  [[-0.00024929]\n",
      " [-0.00024712]]\n",
      "----------------------------------------\n",
      "A1:  [[1.57449155]\n",
      " [1.56074183]]\n",
      "************************************************************\n",
      "A1:  [[1.57449155]\n",
      " [1.56074183]]\n",
      "W2:  [[0.10393963]\n",
      " [0.10393028]]\n",
      "b2:  [[0.10429778]]\n",
      "----------------------------------------\n",
      "A2:  [[0.3258604]]\n",
      "************************************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.09808783 0.09713619]\n",
      " [0.09811233 0.09717028]]\n",
      "b1:  [[-0.00029354]\n",
      " [-0.00028993]]\n",
      "----------------------------------------\n",
      "A1:  [[1.5696503 ]\n",
      " [1.55451995]]\n",
      "************************************************************\n",
      "A1:  [[1.5696503 ]\n",
      " [1.55451995]]\n",
      "W2:  [[0.10467557]\n",
      " [0.10465979]]\n",
      "b2:  [[0.1051272]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32699977]]\n",
      "************************************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.09776654 0.0966007 ]\n",
      " [0.09780266 0.09665416]]\n",
      "b1:  [[-0.00034709]\n",
      " [-0.00034155]]\n",
      "----------------------------------------\n",
      "A1:  [[1.66246461]\n",
      " [1.64285346]]\n",
      "************************************************************\n",
      "A1:  [[1.66246461]\n",
      " [1.64285346]]\n",
      "W2:  [[0.10556603]\n",
      " [0.10554167]]\n",
      "b2:  [[0.10610897]]\n",
      "----------------------------------------\n",
      "A2:  [[0.34888929]]\n",
      "************************************************************\n",
      "Epoch -  2 Loss -  27.943436911874542\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09737585 0.09566305]\n",
      " [0.09742814 0.09575532]]\n",
      "b1:  [[-0.00042523]\n",
      " [-0.00041645]]\n",
      "----------------------------------------\n",
      "A1:  [[1.55843195]\n",
      " [1.531347  ]]\n",
      "************************************************************\n",
      "A1:  [[1.55843195]\n",
      " [1.531347  ]]\n",
      "W2:  [[0.10667176]\n",
      " [0.10663435]]\n",
      "b2:  [[0.10729946]]\n",
      "----------------------------------------\n",
      "A2:  [[0.32953486]]\n",
      "************************************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09710179 0.095389  ]\n",
      " [0.09717202 0.0954992 ]]\n",
      "b1:  [[-0.00045949]\n",
      " [-0.00044846]]\n",
      "----------------------------------------\n",
      "A1:  [[1.55426076]\n",
      " [1.52721578]]\n",
      "************************************************************\n",
      "A1:  [[1.55426076]\n",
      " [1.52721578]]\n",
      "W2:  [[0.10724377]\n",
      " [0.10719642]]\n",
      "b2:  [[0.10756347]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33039686]]\n",
      "************************************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.09679776 0.0949981 ]\n",
      " [0.09688802 0.09513405]]\n",
      "b1:  [[-0.00050292]\n",
      " [-0.00048904]]\n",
      "----------------------------------------\n",
      "A1:  [[1.54966675]\n",
      " [1.52132911]]\n",
      "************************************************************\n",
      "A1:  [[1.54966675]\n",
      " [1.52132911]]\n",
      "W2:  [[0.10796955]\n",
      " [0.10790957]]\n",
      "b2:  [[0.10837653]]\n",
      "----------------------------------------\n",
      "A2:  [[0.3314828]]\n",
      "************************************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.09648242 0.09447253]\n",
      " [0.09659461 0.09464504]]\n",
      "b1:  [[-0.00055548]\n",
      " [-0.00053794]]\n",
      "----------------------------------------\n",
      "A1:  [[1.64154742]\n",
      " [1.60810311]]\n",
      "************************************************************\n",
      "A1:  [[1.64154742]\n",
      " [1.60810311]]\n",
      "W2:  [[0.10884798]\n",
      " [0.10877194]]\n",
      "b2:  [[0.10933879]]\n",
      "----------------------------------------\n",
      "A2:  [[0.35359562]]\n",
      "************************************************************\n",
      "Epoch -  3 Loss -  27.89607154368007\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09609766 0.09354911]\n",
      " [0.09623766 0.09378835]]\n",
      "b1:  [[-0.00063243]\n",
      " [-0.00060933]]\n",
      "----------------------------------------\n",
      "A1:  [[1.53868255]\n",
      " [1.49869965]]\n",
      "************************************************************\n",
      "A1:  [[1.53868255]\n",
      " [1.49869965]]\n",
      "W2:  [[0.10993902]\n",
      " [0.10984075]]\n",
      "b2:  [[0.11050539]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33377955]]\n",
      "************************************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09582903 0.09328047]\n",
      " [0.09599567 0.09354636]]\n",
      "b1:  [[-0.00066601]\n",
      " [-0.00063958]]\n",
      "----------------------------------------\n",
      "A1:  [[1.5347642 ]\n",
      " [1.49488055]]\n",
      "************************************************************\n",
      "A1:  [[1.5347642 ]\n",
      " [1.49488055]]\n",
      "W2:  [[0.11050314]\n",
      " [0.11039021]]\n",
      "b2:  [[0.11075683]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33461643]]\n",
      "************************************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.09553092 0.09289719]\n",
      " [0.09572728 0.09320129]]\n",
      "b1:  [[-0.00070859]\n",
      " [-0.00067792]]\n",
      "----------------------------------------\n",
      "A1:  [[1.53045836]\n",
      " [1.48939611]]\n",
      "************************************************************\n",
      "A1:  [[1.53045836]\n",
      " [1.48939611]]\n",
      "W2:  [[0.11121916]\n",
      " [0.11108763]]\n",
      "b2:  [[0.11155417]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33566978]]\n",
      "************************************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.09522166 0.09238176]\n",
      " [0.09545    0.09273916]]\n",
      "b1:  [[-0.00076014]\n",
      " [-0.00072413]]\n",
      "----------------------------------------\n",
      "A1:  [[1.62150832]\n",
      " [1.57477869]]\n",
      "************************************************************\n",
      "A1:  [[1.62150832]\n",
      " [1.57477869]]\n",
      "W2:  [[0.11208607]\n",
      " [0.11193127]]\n",
      "b2:  [[0.1124977]]\n",
      "----------------------------------------\n",
      "A2:  [[0.35801547]]\n",
      "************************************************************\n",
      "Epoch -  4 Loss -  27.851892899638017\n",
      "A0:  [[8]\n",
      " [8]]\n",
      "W1:  [[0.09484292 0.09147279]\n",
      " [0.09511039 0.0919241 ]]\n",
      "b1:  [[-0.00083589]\n",
      " [-0.00079205]]\n",
      "----------------------------------------\n",
      "A1:  [[1.51962652]\n",
      " [1.46717509]]\n",
      "************************************************************\n",
      "A1:  [[1.51962652]\n",
      " [1.46717509]]\n",
      "W2:  [[0.11316307]\n",
      " [0.11297724]]\n",
      "b2:  [[0.11364143]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33772299]]\n",
      "************************************************************\n",
      "A0:  [[7]\n",
      " [9]]\n",
      "W1:  [[0.09457983 0.0912097 ]\n",
      " [0.09488243 0.09169614]]\n",
      "b1:  [[-0.00086877]\n",
      " [-0.00082055]]\n",
      "----------------------------------------\n",
      "A1:  [[1.51600074]\n",
      " [1.46373314]]\n",
      "************************************************************\n",
      "A1:  [[1.51600074]\n",
      " [1.46373314]]\n",
      "W2:  [[0.1137196 ]\n",
      " [0.11351456]]\n",
      "b2:  [[0.11388078]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33855401]]\n",
      "************************************************************\n",
      "A0:  [[ 6]\n",
      " [10]]\n",
      "W1:  [[0.09428776 0.09083417]\n",
      " [0.0946295  0.09137094]]\n",
      "b1:  [[-0.0009105 ]\n",
      " [-0.00085668]]\n",
      "----------------------------------------\n",
      "A1:  [[1.51202158]\n",
      " [1.45871446]]\n",
      "************************************************************\n",
      "A1:  [[1.51202158]\n",
      " [1.45871446]]\n",
      "W2:  [[0.11442627]\n",
      " [0.11419687]]\n",
      "b2:  [[0.11466301]]\n",
      "----------------------------------------\n",
      "A2:  [[0.33959562]]\n",
      "************************************************************\n",
      "A0:  [[ 5]\n",
      " [12]]\n",
      "W1:  [[0.09398464 0.09032898]\n",
      " [0.09436811 0.09093529]]\n",
      "b1:  [[-0.00096102]\n",
      " [-0.00090025]]\n",
      "----------------------------------------\n",
      "A1:  [[1.60234053]\n",
      " [1.54286834]]\n",
      "************************************************************\n",
      "A1:  [[1.60234053]\n",
      " [1.54286834]]\n",
      "W2:  [[0.11528214]\n",
      " [0.11502256]]\n",
      "b2:  [[0.1155886]]\n",
      "----------------------------------------\n",
      "A2:  [[0.36218591]]\n",
      "************************************************************\n",
      "Epoch -  5 Loss -  27.81052632712487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.09361196, 0.08943454],\n",
       "        [0.09404552, 0.09016107]]),\n",
       " 'b1': array([[-0.00103555],\n",
       "        [-0.00096477]]),\n",
       " 'W2': array([[0.11634574],\n",
       "        [0.11604669]]),\n",
       " 'b2': array([[0.11671047]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs implementation\n",
    "\n",
    "parameters = initialize_parameters([2,2,1])\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "  Loss = []\n",
    "\n",
    "  for j in range(df.shape[0]):\n",
    "\n",
    "    X = df[['cgpa', 'profile_score']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n",
    "    y = df[['lpa']].values[j][0]\n",
    "\n",
    "    # Parameter initialization\n",
    "\n",
    "\n",
    "    y_hat,A1 = L_layers_forward(X,parameters)\n",
    "    y_hat = y_hat[0][0]\n",
    "\n",
    "    update_parameters(parameters,y,y_hat,A1,X)\n",
    "\n",
    "    Loss.append((y-y_hat)**2)\n",
    "\n",
    "  print('Epoch - ',i+1,'Loss - ',np.array(Loss).mean())\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ca84600-639f-4713-a323-4ee7e9fdc7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras \n",
    "from keras import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16daa134-2c8d-43e5-900d-6677e5226f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()\n",
    "model.add(Dense(2,activation='linear',input_dim=2))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2ff82901-46ad-4b2c-ae66-9b75d410f1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94ef0548-08a7-4cff-a435-5f43243251d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.1382056 , -0.10109782],\n",
       "        [-0.29946697,  0.9130758 ]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[-0.21170628],\n",
       "        [-1.1940728 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8885cf6-9c95-405e-b8a9-019acc79fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wegihts = [np.array([[0.1,0.1],[0.1,0.1]],dtype=np.float32)\n",
    "               ,np.array([0. , 0. ] , dtype=np.float32),\n",
    "               np.array([[0.1],[0.1]],dtype=np.float32), \n",
    "               np.array([0.],dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7eb9d1f4-194b-48f9-a849-ef23158c00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_wegihts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebc69afc-0cc2-4123-a915-82173fcacde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af7836e2-0e66-4391-90f7-38bbcc1c2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf44f5b6-e031-402f-97e5-0d6519f803d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 27.4954\n",
      "Epoch 2/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 29.2391 \n",
      "Epoch 3/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.0441 \n",
      "Epoch 4/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.8191 \n",
      "Epoch 5/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.7344  \n",
      "Epoch 6/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.8644  \n",
      "Epoch 7/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.0921 \n",
      "Epoch 8/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25.0778 \n",
      "Epoch 9/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.9551  \n",
      "Epoch 10/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.8269 \n",
      "Epoch 11/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.8718 \n",
      "Epoch 12/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.3410 \n",
      "Epoch 13/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.3215 \n",
      "Epoch 14/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.5858 \n",
      "Epoch 15/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1533 \n",
      "Epoch 16/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.6108 \n",
      "Epoch 17/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.5286 \n",
      "Epoch 18/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.4589 \n",
      "Epoch 19/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.1265\n",
      "Epoch 20/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.6713\n",
      "Epoch 21/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.6348 \n",
      "Epoch 22/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.8150 \n",
      "Epoch 23/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.8563\n",
      "Epoch 24/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.6226 \n",
      "Epoch 25/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.3033\n",
      "Epoch 26/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.1085 \n",
      "Epoch 27/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.8375\n",
      "Epoch 28/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.3610 \n",
      "Epoch 29/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.7460\n",
      "Epoch 30/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.7315\n",
      "Epoch 31/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.0869\n",
      "Epoch 32/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.6005 \n",
      "Epoch 33/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.0162 \n",
      "Epoch 34/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.9629 \n",
      "Epoch 35/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.2133\n",
      "Epoch 36/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.4873\n",
      "Epoch 37/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.0724\n",
      "Epoch 38/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3709 \n",
      "Epoch 39/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.6260 \n",
      "Epoch 40/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.0778 \n",
      "Epoch 41/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.2970 \n",
      "Epoch 42/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7592 \n",
      "Epoch 43/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8473 \n",
      "Epoch 44/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8871  \n",
      "Epoch 45/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6967  \n",
      "Epoch 46/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2224 \n",
      "Epoch 47/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6547 \n",
      "Epoch 48/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3957 \n",
      "Epoch 49/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8852 \n",
      "Epoch 50/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4227 \n",
      "Epoch 51/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5430 \n",
      "Epoch 52/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7638 \n",
      "Epoch 53/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6879 \n",
      "Epoch 54/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5962 \n",
      "Epoch 55/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6024  \n",
      "Epoch 56/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5636 \n",
      "Epoch 57/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4223 \n",
      "Epoch 58/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4649 \n",
      "Epoch 59/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.4405 \n",
      "Epoch 60/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9681 \n",
      "Epoch 61/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0284 \n",
      "Epoch 62/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3752 \n",
      "Epoch 63/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0871 \n",
      "Epoch 64/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3270 \n",
      "Epoch 65/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3407 \n",
      "Epoch 66/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3331 \n",
      "Epoch 67/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1452 \n",
      "Epoch 68/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6289 \n",
      "Epoch 69/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5685 \n",
      "Epoch 70/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1772 \n",
      "Epoch 71/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4659 \n",
      "Epoch 72/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3189 \n",
      "Epoch 73/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3975 \n",
      "Epoch 74/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3027 \n",
      "Epoch 75/75\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1231 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b2da973050>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,0:-1].values,df['lpa'].values,epochs=75,verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0892c9e-6a3d-4e2b-829a-eacb51d54703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.37382805, 0.37382805],\n",
       "        [0.36589366, 0.36589366]], dtype=float32),\n",
       " array([0.27255452, 0.27255452], dtype=float32),\n",
       " array([[0.37317064],\n",
       "        [0.37317064]], dtype=float32),\n",
       " array([0.20489334], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f1d5f-a26a-40b4-bb90-902b66137606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
